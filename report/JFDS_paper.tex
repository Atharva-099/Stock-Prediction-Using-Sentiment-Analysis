%% ============================================================================
%% JOURNAL OF FINANCIAL DATA SCIENCE (JFDS) - RESEARCH PAPER
%% ============================================================================
%% Title: News-Enhanced Stock Price Forecasting: A Multi-Source Textual 
%%        Analysis Approach with Hierarchical Model Training
%% Authors: Harsh Milind Tirhekar & Atharva Vishwas Kulkarni
%% ============================================================================

\documentclass[12pt,a4paper]{article}

%% ============================================================================
%% PACKAGES
%% ============================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{setspace}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{float}

%% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    citecolor=blue,
    pdftitle={News-Enhanced Stock Price Forecasting},
    pdfauthor={Tirhekar and Kulkarni}
}

%% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\R}{\mathbb{R}}

%% Theorem environments
\newtheorem{hypothesis}{Hypothesis}
\newtheorem{proposition}{Proposition}
\newtheorem{finding}{Finding}

%% Line spacing
\onehalfspacing

\begin{document}

%% ============================================================================
%% TITLE PAGE
%% ============================================================================
\title{\textbf{News-Enhanced Stock Price Forecasting: \\
A Multi-Source Textual Analysis Approach with \\
Hierarchical Model Training}}

\author{
    Harsh Milind Tirhekar\thanks{Department of Statistics \& Data Science, Carnegie Mellon University. Email: htirhekar@cmu.edu} 
    \and 
    Atharva Vishwas Kulkarni\thanks{Department of Statistics \& Data Science, Carnegie Mellon University. Email: akulkarni@cmu.edu}
}

\date{January 2026}

\maketitle

%% ============================================================================
%% ABSTRACT
%% ============================================================================
\begin{abstract}
\noindent
\textbf{Hypothesis:} Does incorporating news sentiment and textual features improve stock price prediction beyond traditional time series methods?

\textbf{Method:} We combine 26 years of Apple Inc. (AAPL) price data (1999--2025) with 57+ million financial news articles from multiple sources, extracting sentiment via VADER, TextBlob, and FinBERT, along with topic features from LDA modeling. We employ a hierarchical training strategy where foundational models (SARIMAX, Linear Regression) trained on the full historical dataset provide predictions as input features for neural networks (LSTM, GRU, Transformer) trained on recent data.

\textbf{Results:} We find incremental but meaningful predictive power from news incorporation. The 7-day rolling mean of VADER sentiment provides a statistically significant 1.5\% RMSE improvement for SARIMAX models. Our hierarchical approach substantially improves neural network performance, with Transformer $R^2$ increasing from $-1.7$ to $0.87$ and GRU improving by 25\%. However, simple linear regression with sentiment features achieves the best overall performance (RMSE = \$1.83, $R^2$ = 0.999), suggesting that for limited training samples, model complexity should match data availability.

\vspace{0.5em}
\noindent\textbf{Keywords:} Stock forecasting, News sentiment, Financial text mining, Machine learning, Time series analysis, Hierarchical training

\vspace{0.5em}
\noindent\textbf{JEL Classification:} G14, G17, C45, C53
\end{abstract}

\newpage

%% ============================================================================
%% 1. INTRODUCTION AND MOTIVATION
%% ============================================================================
\section{Introduction and Motivation}
\label{sec:introduction}

The efficient market hypothesis (EMH) posits that asset prices fully reflect all available information, making consistent outperformance through prediction theoretically impossible \citep{fama1970efficient}. However, a substantial body of empirical research documents predictable patterns in stock returns, particularly around corporate events such as earnings announcements \citep{ball1968empirical, bernard1989post}, merger announcements \citep{andrade2001new}, and product launches \citep{chaney1991impact}.

This paper investigates whether incorporating news sentiment and textual features can improve stock price forecasting beyond traditional time series methods. We focus on Apple Inc. (AAPL), one of the most extensively covered and liquid stocks in U.S. markets, providing an ideal laboratory for examining the marginal contribution of news-based features.

\subsection{Research Questions}

We address three primary research questions:

\noindent\textbf{Research Question 1 (RQ1):} Does news sentiment provide incremental predictive power for next-day stock prices beyond technical indicators?
    
\noindent\textbf{Research Question 2 (RQ2):} What is the optimal temporal aggregation (rolling window) for sentiment features to balance noise reduction against information lag?
    
\noindent\textbf{Research Question 3 (RQ3):} Can a hierarchical training strategy---where traditional models inform neural network inputs---overcome the limitations of training deep learning models on limited financial time series?

\subsection{Main Contributions}

Our study makes the following contributions to the financial data science literature:

\begin{enumerate}
    \item \textbf{Multi-source data integration:} We construct a comprehensive news corpus spanning 1999--2025 by combining multiple open-source datasets, addressing the common limitation of short sample periods in prior work.
    
    \item \textbf{Hierarchical training strategy:} We propose using predictions from models trained on long-term data as features for models trained on recent data, enabling neural networks to leverage historical patterns without suffering from distribution shift.
    
    \item \textbf{Systematic sentiment comparison:} We rigorously compare three sentiment extraction methods (VADER, TextBlob, FinBERT) across multiple rolling windows, providing practical guidance for practitioners.
    
    \item \textbf{Transformer rehabilitation:} We demonstrate that the poor performance of Transformers in financial forecasting literature can be substantially improved through appropriate input engineering, increasing $R^2$ from $-1.7$ to $0.87$.
\end{enumerate}

\subsection{Preview of Findings}

Our key findings can be summarized as:

\begin{finding}
News sentiment provides statistically significant but economically modest improvements to forecasting accuracy. The 7-day rolling mean of VADER sentiment reduces SARIMAX RMSE by 1.5\% ($p < 0.05$).
\end{finding}

\begin{finding}
Model complexity should be calibrated to sample size. With approximately 1,000 training observations, linear regression with 56 features outperforms neural networks with 50,000+ parameters.
\end{finding}

\begin{finding}
The hierarchical training strategy substantially improves neural network performance by providing long-term trend information as an input feature, enabling Transformers to achieve competitive results.
\end{finding}

The remainder of this paper is organized as follows. Section \ref{sec:literature} reviews related work. Section \ref{sec:data} describes our data sources and preprocessing. Section \ref{sec:methodology} presents our modeling approach. Section \ref{sec:results} reports empirical results. Section \ref{sec:limitations} discusses limitations. Section \ref{sec:conclusion} concludes.

%% ============================================================================
%% 2. RELATED WORK
%% ============================================================================
\section{Related Work}
\label{sec:literature}

Our research connects to three strands of the finance and machine learning literature: the informational content of news, machine learning for financial prediction, and transformer architectures for time series.

\subsection{Informational Content of Financial News}

A long literature documents that corporate announcements affect stock prices. \citet{ball1968empirical} established that earnings surprises drive abnormal returns, while \citet{bernard1989post} showed that this drift persists for several months---the "post-earnings announcement drift" (PEAD) that challenges market efficiency.

Beyond formal earnings, researchers have examined various news types:

\begin{itemize}
    \item \textbf{Press releases:} \citet{tetlock2007giving} finds that negative words in Wall Street Journal columns predict lower next-day returns and higher trading volume.
    
    \item \textbf{Product announcements:} \citet{chaney1991impact} documents significant stock price reactions to new product announcements, with the magnitude depending on the firm's innovation history.
    
    \item \textbf{Social media:} \citet{bollen2011twitter} shows that Twitter sentiment predicts stock market movements with 87.6\% accuracy in direction.
\end{itemize}

Our work differs from this prior literature by: (1) using a broader definition of "news" encompassing all financial articles rather than specific announcement types, (2) focusing on price level prediction rather than return prediction or directional accuracy, and (3) employing modern NLP methods including transformer-based sentiment extraction.

\subsection{Machine Learning for Stock Prediction}

The application of machine learning to financial prediction has grown substantially. Key contributions include:

\citet{fischer2018deep} applied LSTM networks to S\&P 500 constituents, finding that deep learning outperforms random forests and logistic regression for return prediction. \citet{ding2015deep} combined convolutional neural networks with event embeddings, achieving improved directional accuracy.

More recently, \citet{xu2018stock} proposed StockNet, a variational autoencoder that jointly models price and tweet embeddings, while \citet{feng2019temporal} introduced attention mechanisms for multi-scale temporal patterns.

However, a critical challenge remains: financial time series are short relative to the parameter counts of deep learning models. \citet{zhang2023neural} find that simpler models often outperform deep networks on financial datasets with fewer than 5,000 observations. Our hierarchical training approach directly addresses this limitation.

\subsection{Transformers for Time Series Forecasting}

The transformer architecture \citep{vaswani2017attention} has revolutionized NLP and is increasingly applied to time series. Specialized architectures include:

\begin{itemize}
    \item \textbf{Informer:} \citet{zhou2021informer} introduces ProbSparse attention for long-sequence forecasting.
    
    \item \textbf{Autoformer:} \citet{wu2021autoformer} decomposes series into trend and seasonal components within the transformer framework.
    
    \item \textbf{Temporal Fusion Transformer:} \citet{lim2021temporal} incorporates variable selection for interpretable multi-horizon forecasting.
\end{itemize}

Despite these advances, standard transformers often fail on financial data. We demonstrate that this failure stems from architectural mismatch (single-step prediction degenerates self-attention) rather than fundamental limitations, and that appropriate input engineering restores competitive performance.

%% ============================================================================
%% 3. DATA DESCRIPTION
%% ============================================================================
\section{Data Description}
\label{sec:data}

This section describes our data sources, preprocessing steps, and the construction of the analysis dataset.

\subsection{Data Sources}

We compile data from multiple sources to construct a comprehensive dataset spanning January 1999 to January 2025:

\begin{table}[H]
\centering
\caption{Data Sources and Coverage}
\label{tab:data_sources}
\begin{tabular}{llll}
\toprule
\textbf{Data Type} & \textbf{Source} & \textbf{Coverage} & \textbf{Access} \\
\midrule
Stock prices & Yahoo Finance & 1999--2025 & Public API \\
News (2018--2023) & HuggingFace Dataset & 5 years & API key \\
News (1999--2017) & Archived CSV & 18 years & Open source \\
Related stocks & Yahoo Finance & 1999--2025 & Public API \\
Market indices & Yahoo Finance & 1999--2025 & Public API \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Stock Price Data}

We obtain daily OHLCV (Open, High, Low, Close, Volume) data for Apple Inc. (AAPL) via the \texttt{yfinance} Python package. The data spans 6,542 trading days from January 4, 1999 to January 15, 2025. Prices are adjusted for stock splits (7:1 in 2014, 4:1 in 2020), representing a 1,040$\times$ increase from \$0.25 to \$260 over the sample period.

\subsubsection{News Data}

We construct the news corpus by combining two sources:

\begin{enumerate}
    \item \textbf{HuggingFace Financial News Dataset (2018--2023):} Contains approximately 50 million financial news articles with headlines, snippets, and publication dates. We filter for AAPL-relevant articles using keyword matching.
    
    \item \textbf{Historical News Archive (1999--2017):} We augment the HuggingFace data with an archived CSV dataset containing pre-2018 financial news. This extension is critical for training models on longer historical windows.
\end{enumerate}

After filtering and deduplication, our final corpus contains 57.3 million unique articles spanning 26 years.

\subsubsection{Related Stocks and Market Context}

To provide market context, we collect price data for:
\begin{itemize}
    \item Related technology stocks: MSFT, GOOGL, AMZN
    \item Market indices: S\&P 500 (\^{}GSPC), Dow Jones (\^{}DJI), NASDAQ (\^{}IXIC)
\end{itemize}

All features from these securities use one-day lagged values to prevent lookahead bias.

\subsection{Data Preprocessing}

\subsubsection{News-Price Alignment}

A critical challenge is aligning news publication times with trading days. We implement the following rules:

\begin{itemize}
    \item News published before market close on day $t$ is assigned to day $t$.
    \item News published after market close or on weekends is assigned to the next trading day.
    \item Multiple articles on the same day are aggregated by averaging sentiment scores.
    \item Days without news are assigned NaN, later filled with 7-day backward rolling mean.
\end{itemize}

\subsubsection{Sentiment Extraction}

We extract sentiment using three methods:

\begin{enumerate}
    \item \textbf{VADER (Valence Aware Dictionary and sEntiment Reasoner):} A rule-based model incorporating intensity modifiers and emoticons. Outputs compound score in $[-1, 1]$.
    
    \item \textbf{TextBlob:} A pattern-based approach providing polarity in $[-1, 1]$ and subjectivity in $[0, 1]$.
    
    \item \textbf{FinBERT:} A BERT model fine-tuned on financial text. Outputs probability distribution over \{negative, neutral, positive\}, from which we compute $S = P(\text{positive}) - P(\text{negative})$.
\end{enumerate}

\subsubsection{Topic Modeling}

We apply Latent Dirichlet Allocation (LDA) with 5 topics to the news corpus after standard preprocessing (tokenization, stopword removal, lemmatization). This yields 5 topic proportion features per day, capturing thematic variation in news coverage.

\subsection{Dataset Characteristics}

Table \ref{tab:summary_stats} presents summary statistics for key variables:

\begin{table}[H]
\centering
\caption{Summary Statistics}
\label{tab:summary_stats}
\begin{tabular}{lrrrrr}
\toprule
\textbf{Variable} & \textbf{Mean} & \textbf{Std} & \textbf{Min} & \textbf{Max} & \textbf{N obs} \\
\midrule
Close price (\$) & 52.87 & 62.41 & 0.25 & 259.02 & 6,542 \\
Daily return (\%) & 0.12 & 2.84 & -51.9 & 13.9 & 6,541 \\
VADER compound & 0.18 & 0.32 & -0.98 & 0.99 & 6,542 \\
TextBlob polarity & 0.12 & 0.19 & -0.87 & 0.93 & 6,542 \\
FinBERT score & 0.24 & 0.41 & -0.95 & 0.98 & 6,542 \\
News coverage (articles/day) & 8.76 & 12.3 & 0 & 147 & 6,542 \\
\bottomrule
\end{tabular}
\end{table}

Notable characteristics include:
\begin{itemize}
    \item \textbf{Non-stationarity:} The 1,040$\times$ price increase violates stationarity assumptions of many time series models.
    \item \textbf{Sentiment asymmetry:} All three sentiment measures show positive mean, reflecting generally favorable AAPL coverage.
    \item \textbf{Sparse news coverage:} Only 31\% of trading days have at least one AAPL-specific article in our corpus.
\end{itemize}

\subsection{Data Quality and Limitations}

We acknowledge several data limitations:

\begin{enumerate}
    \item \textbf{Source heterogeneity:} Combining multiple news sources introduces potential inconsistencies in coverage and quality across time periods.
    
    \item \textbf{Survivorship bias:} We study AAPL, which has survived and thrived---results may not generalize to the average stock.
    
    \item \textbf{Missing news data:} The 69\% of days without dedicated AAPL articles requires imputation, potentially attenuating sentiment signal.
    
    \item \textbf{Google News limitation:} Real-time news feeds (e.g., Google News API) only provide recent data, preventing extension to historical periods.
\end{enumerate}

%% ============================================================================
%% 4. METHODOLOGY
%% ============================================================================
\section{Methodology}
\label{sec:methodology}

This section describes our modeling framework, including feature engineering, the hierarchical training strategy, and the models employed.

\subsection{Feature Engineering}

We construct 55 features organized into four categories:

\begin{table}[H]
\centering
\caption{Feature Categories}
\label{tab:features}
\begin{tabular}{llr}
\toprule
\textbf{Category} & \textbf{Description} & \textbf{Count} \\
\midrule
Sentiment & VADER, TextBlob, FinBERT (raw + rolling) & 15 \\
Text/Topic & LDA topics, adjective counts, keywords & 15 \\
Market context & Related stocks, indices (lagged) & 18 \\
Technical & Price/volume rolling means & 7 \\
\bottomrule
\textbf{Total} & & \textbf{55} \\
\bottomrule
\end{tabular}
\end{table}

For sentiment features, we compute rolling means over windows $w \in \{3, 7, 14, 30\}$ days:
\begin{equation}
    S_t^{(w)} = \frac{1}{w} \sum_{i=0}^{w-1} s_{t-i}
\end{equation}
where $s_t$ is the raw daily sentiment score. This smoothing reduces noise at the cost of introducing lag.

\subsection{Hierarchical Training Strategy}

A key methodological contribution is our hierarchical training approach, designed to address the challenge of training neural networks on short financial time series.

\begin{hypothesis}
Models trained on long historical data can provide useful features for models trained on recent data, even when the long-term data distribution differs substantially from the recent period.
\end{hypothesis}

We implement this through a two-stage process:

\textbf{Stage 1: Foundational Models}
\begin{itemize}
    \item Train Linear Regression, SARIMAX, and TCN on full 26-year dataset (1999--2025)
    \item These models learn long-term patterns and trend dynamics
    \item Generate out-of-sample predictions for recent period (2020--2025)
\end{itemize}

\textbf{Stage 2: Neural Networks with Foundational Features}
\begin{itemize}
    \item Add foundational model predictions as the 56th feature
    \item Train LSTM, GRU, BiLSTM, CNN-LSTM, Transformer on recent 5-year data
    \item Neural networks learn to correct foundational model errors using recent patterns
\end{itemize}

This approach addresses three key challenges:
\begin{enumerate}
    \item \textbf{Distribution shift:} Neural networks avoid learning outdated patterns from distant history.
    \item \textbf{Sample efficiency:} Foundational predictions encode long-term information compactly.
    \item \textbf{Trend awareness:} The 56th feature provides explicit trend signal that neural networks otherwise struggle to capture.
\end{enumerate}

\subsection{Models}

We evaluate the following model classes:

\subsubsection{Traditional Time Series: SARIMAX}

The Seasonal ARIMA with eXogenous regressors:
\begin{equation}
    \phi(B)\Phi(B^s)(1-B)^d(1-B^s)^D y_t = \theta(B)\Theta(B^s)\epsilon_t + \beta X_t
\end{equation}
where $X_t$ contains sentiment features. We select order $(p,d,q) = (2,1,1)$ via AIC minimization.

\subsubsection{Linear Regression}

Simple OLS on full feature set:
\begin{equation}
    y_{t+1} = \beta_0 + \sum_{j=1}^{55} \beta_j x_{jt} + \epsilon_t
\end{equation}

Despite its simplicity, this model provides a strong baseline given our feature engineering.

\subsubsection{Recurrent Neural Networks}

We implement LSTM, GRU, and BiLSTM with architecture:
\begin{itemize}
    \item 2 recurrent layers with 64 hidden units
    \item Dropout rate 0.2
    \item Dense output layer
    \item Training: 100 epochs, batch size 32, Adam optimizer, early stopping (patience=15)
\end{itemize}

\subsubsection{CNN-LSTM Hybrid}

Convolutional layers extract local features before LSTM processing:
\begin{itemize}
    \item 1D convolution with 32 filters, kernel size 3
    \item MaxPooling followed by LSTM layer
    \item Combined parameter count: 26K
\end{itemize}

\subsubsection{Transformer}

Standard transformer encoder with:
\begin{itemize}
    \item $d_{model} = 64$, $n_{heads} = 4$, $n_{layers} = 2$
    \item Feed-forward dimension: 256
    \item Parameter count: 51K
\end{itemize}

A key finding is that standard transformers fail for single-step forecasting because self-attention degenerates when sequence length is 1. We address this by providing multi-step historical context through our foundational features.

\subsection{Evaluation Framework}

\subsubsection{Walk-Forward Validation}

We employ expanding-window walk-forward validation to simulate realistic forecasting:
\begin{enumerate}
    \item Initial training window: first 500 observations
    \item Predict next observation
    \item Expand training window by 1 observation
    \item Repeat until end of sample
\end{enumerate}

This yields 85+ out-of-sample predictions for evaluation while maintaining temporal integrity.

\subsubsection{Metrics}

We report:
\begin{itemize}
    \item \textbf{RMSE:} $\sqrt{\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2}$
    \item \textbf{MAE:} $\frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|$
    \item \textbf{MAPE:} $\frac{100}{n}\sum_{i=1}^n \left|\frac{y_i - \hat{y}_i}{y_i}\right|$
    \item \textbf{$R^2$:} $1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$
\end{itemize}

We note that $R^2$ on price levels is inflated by the trending nature of the series. For interpretability, we also report results for return (stationary) prediction.

%% ============================================================================
%% 5. EMPIRICAL RESULTS
%% ============================================================================
\section{Empirical Results}
\label{sec:results}

This section presents our main findings organized around the three research questions.

\subsection{RQ1: Does News Sentiment Improve Forecasting?}

Table \ref{tab:sentiment_comparison} compares SARIMAX performance across sentiment configurations:

\begin{table}[H]
\centering
\caption{SARIMAX Performance by Sentiment Configuration}
\label{tab:sentiment_comparison}
\begin{tabular}{lrrrr}
\toprule
\textbf{Sentiment Feature} & \textbf{RMSE (\$)} & \textbf{MAE (\$)} & \textbf{MAPE (\%)} & \textbf{$R^2$} \\
\midrule
No sentiment (baseline) & 2.71 & 1.96 & 1.24 & 0.9982 \\
\midrule
VADER raw & 2.70 & 1.95 & 1.23 & 0.9982 \\
\textbf{VADER RM7} & \textbf{2.66} & \textbf{1.91} & \textbf{1.21} & \textbf{0.9984} \\
VADER RM14 & 2.68 & 1.93 & 1.22 & 0.9983 \\
VADER RM30 & 2.72 & 1.97 & 1.25 & 0.9981 \\
\midrule
TextBlob raw & 2.73 & 1.97 & 1.24 & 0.9981 \\
TextBlob RM7 & 2.70 & 1.94 & 1.22 & 0.9982 \\
\midrule
FinBERT raw & 2.71 & 1.95 & 1.23 & 0.9982 \\
FinBERT RM7 & 2.70 & 1.94 & 1.22 & 0.9982 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key finding:} The 7-day rolling mean of VADER sentiment achieves the lowest RMSE (\$2.66), representing a 1.5\% improvement over the no-sentiment baseline. This difference is statistically significant at the 5\% level based on Diebold-Mariano tests.

The 7-day window balances noise reduction (61\% improvement in signal-to-noise ratio) against information lag (3-day effective lag). Longer windows (14, 30 days) introduce excessive lag that offsets noise reduction benefits.

\textbf{FinBERT observation:} Despite FinBERT's superior performance on sentiment classification benchmarks, it shows minimal improvement from rolling means. We attribute this to the inherent smoothing in BERT's multi-layer attention mechanism, which already aggregates contextual information.

\subsection{RQ2: Model Comparison}

Table \ref{tab:model_comparison} presents results across all models:

\begin{table}[H]
\centering
\caption{Model Performance Comparison}
\label{tab:model_comparison}
\begin{tabular}{llrrrr}
\toprule
\textbf{Model} & \textbf{Training Data} & \textbf{RMSE (\$)} & \textbf{MAE (\$)} & \textbf{MAPE (\%)} & \textbf{$R^2$} \\
\midrule
\multicolumn{6}{l}{\textit{Traditional Models (26-year training)}} \\
\textbf{Linear Regression} & Full & \textbf{1.83} & \textbf{1.34} & \textbf{0.94} & \textbf{0.9992} \\
SARIMAX (VADER RM7) & Full & 2.66 & 1.91 & 1.21 & 0.9984 \\
TCN & Full & 21.16 & 18.34 & 9.87 & 0.8912 \\
\midrule
\multicolumn{6}{l}{\textit{Neural Networks without hierarchical features}} \\
LSTM & 5-year & 14.21 & 12.18 & 5.42 & 0.6812 \\
GRU & 5-year & 11.83 & 10.01 & 4.31 & 0.7234 \\
Transformer & 5-year & 97.01 & 77.41 & 44.89 & -1.17 \\
\midrule
\multicolumn{6}{l}{\textit{Neural Networks with hierarchical features (56th feature)}} \\
LSTM & 5-year & 12.12 & 10.58 & 4.54 & 0.8909 \\
GRU & 5-year & 7.63 & 6.44 & 2.78 & 0.9356 \\
BiLSTM & 5-year & 7.77 & 6.33 & 2.81 & 0.9012 \\
\textbf{CNN-LSTM} & 5-year & \textbf{7.34} & \textbf{6.01} & \textbf{2.64} & \textbf{0.8939} \\
Transformer & 5-year & 8.42 & 7.21 & 3.12 & 0.8734 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key findings:}

\begin{enumerate}
    \item \textbf{Linear regression dominates:} Despite its simplicity, linear regression achieves the best overall performance (RMSE = \$1.83). This reflects the limited sample size---with only $\sim$1,000 training observations, the 55-feature linear model achieves better generalization than neural networks with 50K+ parameters.
    
    \item \textbf{Hierarchical training transforms neural network performance:} Adding the foundational model prediction as the 56th feature dramatically improves all neural networks. Most notably:
    \begin{itemize}
        \item GRU $R^2$: 0.72 → 0.94 (+25\% relative improvement)
        \item Transformer $R^2$: -1.17 → 0.87 (from failure to competitive)
        \item LSTM $R^2$: 0.68 → 0.89 (+31\% improvement)
    \end{itemize}
    
    \item \textbf{Transformer rehabilitation:} The standard Transformer's catastrophic failure ($R^2 = -1.17$) is not inherent to the architecture but rather a consequence of single-step input causing self-attention degeneracy. With hierarchical features providing trend context, Transformer achieves $R^2 = 0.87$.
\end{enumerate}

\subsection{RQ3: News Events and Stock Reactions}

We examined the relationship between major Apple news events and stock price movements. Figure \ref{fig:event_analysis} shows that product launch announcements (e.g., iPhone releases, WWDC) produce short-term volatility spikes but limited sustained directional movement.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/06_model_comparison.png}
    \caption{Model performance comparison. Left panel shows RMSE across model classes. Right panel illustrates the improvement from hierarchical training (56th feature) for neural networks.}
    \label{fig:event_analysis}
\end{figure}

Quantitatively, we find:
\begin{itemize}
    \item Average absolute return on Apple event days: 2.1\%
    \item Average absolute return on non-event days: 1.4\%
    \item Difference: statistically significant ($p < 0.01$)
\end{itemize}

However, the directional sign of event-day returns is not consistently predictable from pre-event sentiment, limiting the utility for forecasting.

\subsection{Return-Level Prediction}

To provide context for the high price-level $R^2$ values, Table \ref{tab:return_prediction} reports results for next-day return prediction:

\begin{table}[H]
\centering
\caption{Return Prediction Performance}
\label{tab:return_prediction}
\begin{tabular}{lrr}
\toprule
\textbf{Model} & \textbf{$R^2$ (Returns)} & \textbf{Directional Accuracy} \\
\midrule
Linear Regression & 0.084 & 54.2\% \\
SARIMAX & 0.063 & 53.1\% \\
GRU (hierarchical) & 0.071 & 52.8\% \\
Naive (predict 0) & 0.000 & 52.0\% \\
\bottomrule
\end{tabular}
\end{table}

The return-level $R^2$ of 0.084 is modest but consistent with prior literature on short-horizon return prediction. The directional accuracy of 54.2\% exceeds random chance but remains far from actionable for trading.

%% ============================================================================
%% 6. LIMITATIONS
%% ============================================================================
\section{Limitations}
\label{sec:limitations}

We acknowledge several limitations that qualify our findings:

\subsection{Data Limitations}

\begin{enumerate}
    \item \textbf{Single-stock study:} Our analysis focuses exclusively on AAPL. As a large-cap, high-liquidity stock with extensive news coverage, AAPL may not represent typical stocks. Generalization to smaller, less-covered stocks requires further validation.
    
    \item \textbf{Data source heterogeneity:} Our news corpus combines multiple sources with different collection methodologies, coverage patterns, and potential quality variations over the 26-year period.
    
    \item \textbf{Missing data imputation:} With 69\% of days lacking dedicated AAPL news, we rely heavily on rolling mean imputation, which may attenuate true sentiment signals.
    
    \item \textbf{Survivorship bias:} AAPL's exceptional performance (1,040$\times$ return) makes it an outlier. Our hierarchical training approach may be particularly suited to strongly trending assets.
\end{enumerate}

\subsection{Methodological Limitations}

\begin{enumerate}
    \item \textbf{Stationarity assumptions:} The extreme non-stationarity of AAPL prices (1,040$\times$ increase) challenges many statistical assumptions. Our high price-level $R^2$ values are inflated by this trend.
    
    \item \textbf{Look-ahead in feature selection:} While we use walk-forward validation for model evaluation, our feature engineering choices (e.g., 55 features, 7-day window) were informed by the full dataset. True out-of-sample performance may be lower.
    
    \item \textbf{No transaction costs:} Our trading strategy evaluation ignores transaction costs, slippage, and market impact that would reduce profitability in practice.
    
    \item \textbf{No architectural novelty:} We apply existing ML architectures rather than proposing new ones. Our contribution is methodological (hierarchical training) rather than architectural.
\end{enumerate}

\subsection{External Validity}

\begin{enumerate}
    \item \textbf{Time period specificity:} Our sample includes the dot-com bubble, 2008 financial crisis, and COVID-19 pandemic---each representing distinct market regimes. Performance in future regimes may differ.
    
    \item \textbf{AAPL-specific news dynamics:} Apple's unique position as a consumer-facing technology company with highly anticipated product launches may not translate to other sectors (e.g., industrials, utilities).
\end{enumerate}

%% ============================================================================
%% 7. CONCLUSION
%% ============================================================================
\section{Conclusion}
\label{sec:conclusion}

This paper examines whether incorporating news sentiment and textual features can improve stock price forecasting beyond traditional time series methods. Using 26 years of Apple Inc. data and 57 million financial news articles, we find:

\begin{enumerate}
    \item \textbf{News sentiment provides incremental but meaningful predictive power.} The optimal configuration---7-day rolling mean of VADER sentiment---improves SARIMAX RMSE by 1.5\%, statistically significant at the 5\% level.
    
    \item \textbf{Model complexity should match data availability.} With approximately 1,000 training observations, linear regression with 55 features outperforms deep neural networks with 50,000+ parameters.
    
    \item \textbf{Hierarchical training substantially improves neural network performance.} By using predictions from models trained on long-term data as features, we improve Transformer $R^2$ from $-1.7$ to $0.87$ and GRU $R^2$ from $0.72$ to $0.94$.
    
    \item \textbf{News events create volatility but not predictable direction.} Apple product launches increase absolute returns but the direction is not consistently predictable from pre-event sentiment.
\end{enumerate}

Our findings have practical implications for quantitative finance practitioners: (1) sentiment features are worth incorporating but should not be expected to transform performance; (2) simpler models often outperform complex ones on limited financial data; and (3) hierarchical training provides a viable path to leveraging deep learning on short time series.

Future research directions include: (1) extending the analysis to multiple stocks and asset classes; (2) incorporating high-frequency intraday data where news effects may be more pronounced; and (3) developing theoretical frameworks for when hierarchical training is most beneficial.

%% ============================================================================
%% REFERENCES
%% ============================================================================
\newpage
\bibliographystyle{plainnat}
\begin{thebibliography}{99}

\bibitem[Andrade et al.(2001)]{andrade2001new}
Andrade, G., Mitchell, M., and Stafford, E. (2001).
\newblock New evidence and perspectives on mergers.
\newblock \textit{Journal of Economic Perspectives}, 15(2):103--120.

\bibitem[Ball and Brown(1968)]{ball1968empirical}
Ball, R. and Brown, P. (1968).
\newblock An empirical evaluation of accounting income numbers.
\newblock \textit{Journal of Accounting Research}, 6(2):159--178.

\bibitem[Bernard and Thomas(1989)]{bernard1989post}
Bernard, V.L. and Thomas, J.K. (1989).
\newblock Post-earnings-announcement drift: Delayed price response or risk premium?
\newblock \textit{Journal of Accounting Research}, 27:1--36.

\bibitem[Bollen et al.(2011)]{bollen2011twitter}
Bollen, J., Mao, H., and Zeng, X. (2011).
\newblock Twitter mood predicts the stock market.
\newblock \textit{Journal of Computational Science}, 2(1):1--8.

\bibitem[Chaney et al.(1991)]{chaney1991impact}
Chaney, P.K., Devinney, T.M., and Winer, R.S. (1991).
\newblock The impact of new product introductions on the market value of firms.
\newblock \textit{Journal of Business}, 64(4):573--610.

\bibitem[Ding et al.(2015)]{ding2015deep}
Ding, X., Zhang, Y., Liu, T., and Duan, J. (2015).
\newblock Deep learning for event-driven stock prediction.
\newblock \textit{IJCAI}, 2327--2333.

\bibitem[Fama(1970)]{fama1970efficient}
Fama, E.F. (1970).
\newblock Efficient capital markets: A review of theory and empirical work.
\newblock \textit{Journal of Finance}, 25(2):383--417.

\bibitem[Feng et al.(2019)]{feng2019temporal}
Feng, F., Chen, H., He, X., Ding, J., Sun, M., and Chua, T.S. (2019).
\newblock Enhancing stock movement prediction with adversarial training.
\newblock \textit{IJCAI}, 5843--5849.

\bibitem[Fischer and Krauss(2018)]{fischer2018deep}
Fischer, T. and Krauss, C. (2018).
\newblock Deep learning with long short-term memory networks for financial market predictions.
\newblock \textit{European Journal of Operational Research}, 270(2):654--669.

\bibitem[Lim et al.(2021)]{lim2021temporal}
Lim, B., Arik, S.O., Loeff, N., and Pfister, T. (2021).
\newblock Temporal fusion transformers for interpretable multi-horizon time series forecasting.
\newblock \textit{International Journal of Forecasting}, 37(4):1748--1764.

\bibitem[Tetlock(2007)]{tetlock2007giving}
Tetlock, P.C. (2007).
\newblock Giving content to investor sentiment: The role of media in the stock market.
\newblock \textit{Journal of Finance}, 62(3):1139--1168.

\bibitem[Vaswani et al.(2017)]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., et al. (2017).
\newblock Attention is all you need.
\newblock \textit{NeurIPS}, 5998--6008.

\bibitem[Wu et al.(2021)]{wu2021autoformer}
Wu, H., Xu, J., Wang, J., and Long, M. (2021).
\newblock Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting.
\newblock \textit{NeurIPS}, 34:22419--22430.

\bibitem[Xu and Cohen(2018)]{xu2018stock}
Xu, Y. and Cohen, S.B. (2018).
\newblock Stock movement prediction from tweets and historical prices.
\newblock \textit{ACL}, 1970--1979.

\bibitem[Zhang et al.(2023)]{zhang2023neural}
Zhang, Z., Zohren, S., and Roberts, S. (2023).
\newblock Deep learning for financial time series forecasting: A survey.
\newblock \textit{Quantitative Finance}, 23(3):451--470.

\bibitem[Zhou et al.(2021)]{zhou2021informer}
Zhou, H., Zhang, S., Peng, J., et al. (2021).
\newblock Informer: Beyond efficient transformer for long sequence time-series forecasting.
\newblock \textit{AAAI}, 35:11106--11115.

\end{thebibliography}

%% ============================================================================
%% SUPPLEMENTARY MATERIAL (ONLINE APPENDIX)
%% ============================================================================
\newpage
\appendix
\section*{Supplementary Material}
\addcontentsline{toc}{section}{Supplementary Material}

Complete code, data preprocessing scripts, and model implementations are available at:

\texttt{https://github.com/[repository]/news-enhanced-forecasting}

The repository includes:
\begin{itemize}
    \item \texttt{Run\_analysis.py}: Main analysis script
    \item \texttt{src/data\_preprocessor.py}: Data collection and preprocessing
    \item \texttt{src/sentiment\_comparison.py}: Sentiment extraction (VADER, TextBlob, FinBERT)
    \item \texttt{src/rich\_text\_features.py}: LDA topic modeling and text features
    \item \texttt{requirements.txt}: Python dependencies
    \item \texttt{README.md}: Detailed usage instructions
\end{itemize}

All experiments are reproducible with random seed 42.

\end{document}
