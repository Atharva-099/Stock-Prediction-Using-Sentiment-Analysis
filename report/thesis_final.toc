\babel@toc {english}{}\relax 
\contentsline {chapter}{Abstract}{1}{chapter*.1}%
\contentsline {chapter}{List of Figures}{8}{chapter*.3}%
\contentsline {chapter}{List of Tables}{10}{chapter*.4}%
\contentsline {chapter}{\numberline {1}Introduction and Problem Statement}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Research Objectives}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Professor's Requirements}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}Literature Review}{6}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Sentiment Analysis in Financial Markets}{6}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Deep Learning for Financial Time Series}{7}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Why News Coverage Improves Forecasts}{8}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Comparison with Prior AAPL Studies}{9}{subsection.1.3.4}%
\contentsline {chapter}{\numberline {2}Data Collection and Preprocessing}{10}{chapter.2}%
\contentsline {section}{\numberline {2.1}Stock Price Data Acquisition}{10}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Data Source and API}{10}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Data Fields Specification}{11}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Descriptive Statistics}{11}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Daily Returns Calculation}{12}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}Stationarity Analysis}{13}{subsection.2.1.5}%
\contentsline {section}{\numberline {2.2}Financial News Data Collection}{16}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Data Sources Overview}{16}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}HuggingFace Dataset Specification}{17}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}News Coverage Analysis}{18}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Sentiment Analysis Methods}{18}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}TextBlob Polarity}{18}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}VADER Compound Score}{19}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Daily Sentiment Aggregation}{21}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Sentiment Validation}{21}{subsection.2.3.4}%
\contentsline {section}{\numberline {2.4}Related Stocks and Market Indices}{22}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Stock Selection Rationale}{22}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Market Indices}{22}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Lookahead Bias Prevention}{23}{subsection.2.4.3}%
\contentsline {section}{\numberline {2.5}Dataset Splitting: Foundational Model Strategy}{24}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}The Non-Stationarity Challenge}{24}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Stage 1: Foundational Models (26-Year Data)}{24}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}Stage 2: Neural Networks (5-Year Data + Foundational Features)}{25}{subsection.2.5.3}%
\contentsline {chapter}{\numberline {3}Feature Engineering}{27}{chapter.3}%
\contentsline {section}{\numberline {3.1}Feature Overview}{27}{section.3.1}%
\contentsline {section}{\numberline {3.2}Sentiment Features (10 Total)}{28}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Raw Sentiment Scores (2 features)}{28}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Rolling Mean Sentiment Features (8 features)}{28}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Optimal Window Selection (Requirement 1 Results)}{30}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Text Features (29 Total)}{30}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Latent Dirichlet Allocation (5 features)}{30}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Adjective-Based Features (6 features)}{32}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Financial Keyword Features (18 features)}{33}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}Market Context Features (21 Total)}{33}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Lagged Return Features (12 features)}{33}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Rolling Correlation Features (3 features)}{34}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Market Index Features (9 features)}{34}{subsection.3.4.3}%
\contentsline {section}{\numberline {3.5}Price-Based Features (8 Total)}{35}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Price Rolling Means (4 features)}{35}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Volume Rolling Means (4 features)}{35}{subsection.3.5.2}%
\contentsline {section}{\numberline {3.6}The 16th Feature: Hybrid Strategy}{35}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}Mathematical Formulation}{35}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Residual Learning Transformation}{36}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Theoretical Justification}{36}{subsection.3.6.3}%
\contentsline {subsection}{\numberline {3.6.4}Why GRU Benefits Most}{36}{subsection.3.6.4}%
\contentsline {subsection}{\numberline {3.6.5}Empirical Verification}{37}{subsection.3.6.5}%
\contentsline {section}{\numberline {3.7}Feature Scaling}{37}{section.3.7}%
\contentsline {chapter}{\numberline {4}Baseline Models and Comparisons}{39}{chapter.4}%
\contentsline {section}{\numberline {4.1}Naive Persistence Forecast}{39}{section.4.1}%
\contentsline {section}{\numberline {4.2}Random Walk Model}{39}{section.4.2}%
\contentsline {section}{\numberline {4.3}ARIMA (No Sentiment)}{40}{section.4.3}%
\contentsline {section}{\numberline {4.4}Linear Regression }{40}{section.4.4}%
\contentsline {section}{\numberline {4.5}Complete Baseline Comparison}{41}{section.4.5}%
\contentsline {chapter}{\numberline {5}SARIMAX Model}{42}{chapter.5}%
\contentsline {section}{\numberline {5.1}Mathematical Formulation}{42}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Our Configuration: ARIMA(2, 1, 1) + Exogenous}{43}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}Order Selection}{43}{section.5.2}%
\contentsline {section}{\numberline {5.3}Walk-Forward Validation}{43}{section.5.3}%
\contentsline {section}{\numberline {5.4}SARIMAX Results}{44}{section.5.4}%
\contentsline {chapter}{\numberline {6}Neural Network Models}{45}{chapter.6}%
\contentsline {section}{\numberline {6.1}Data Preprocessing}{45}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}MinMax Scaling}{45}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Sequence Formation}{45}{subsection.6.1.2}%
\contentsline {section}{\numberline {6.2}LSTM (Long Short-Term Memory)}{46}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Architecture}{46}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Complete Gate Equations}{46}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}GRU (Gated Recurrent Unit)}{47}{section.6.3}%
\contentsline {section}{\numberline {6.4}Transformer Analysis (Requirement 6)}{48}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Self-Attention Mechanism}{48}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Ablation Study Results (Requirement 6)}{48}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Root Cause Analysis}{48}{subsection.6.4.3}%
\contentsline {subsection}{\numberline {6.4.4}Corrected Implementation: Temporal Transformer}{49}{subsection.6.4.4}%
\contentsline {section}{\numberline {6.5}Neural Network Training}{49}{section.6.5}%
\contentsline {section}{\numberline {6.6}Neural Network Results Summary}{49}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}Architecture Comparison}{49}{subsection.6.6.1}%
\contentsline {subsection}{\numberline {6.6.2}Performance Results}{50}{subsection.6.6.2}%
\contentsline {chapter}{\numberline {7}Ensemble Methods}{51}{chapter.7}%
\contentsline {section}{\numberline {7.1}Motivation}{51}{section.7.1}%
\contentsline {section}{\numberline {7.2}Weighted Averaging}{51}{section.7.2}%
\contentsline {section}{\numberline {7.3}Diversity Analysis}{51}{section.7.3}%
\contentsline {section}{\numberline {7.4}Ensemble Results}{52}{section.7.4}%
\contentsline {chapter}{\numberline {8}Evaluation Metrics}{53}{chapter.8}%
\contentsline {section}{\numberline {8.1}Mean Absolute Error (MAE)}{53}{section.8.1}%
\contentsline {section}{\numberline {8.2}Root Mean Squared Error (RMSE)}{53}{section.8.2}%
\contentsline {section}{\numberline {8.3}Mean Absolute Percentage Error (MAPE)}{54}{section.8.3}%
\contentsline {section}{\numberline {8.4}Coefficient of Determination ($R^2$)}{54}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Critical Caveat: $R^2$ on Trending Series}{54}{subsection.8.4.1}%
\contentsline {section}{\numberline {8.5}Sharpe Ratio}{55}{section.8.5}%
\contentsline {chapter}{\numberline {9}Trading Strategy Evaluation}{56}{chapter.9}%
\contentsline {section}{\numberline {9.1}Strategy Definition}{56}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Position Rule}{56}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Position Sizing}{56}{subsection.9.1.2}%
\contentsline {section}{\numberline {9.2}Transaction Cost Model}{57}{section.9.2}%
\contentsline {section}{\numberline {9.3}Strategy Performance}{57}{section.9.3}%
\contentsline {section}{\numberline {9.4}Robustness Checks}{58}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Sensitivity to Transaction Costs}{58}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}Performance by Market Regime}{58}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}Bootstrap Confidence Interval}{58}{subsection.9.4.3}%
\contentsline {section}{\numberline {9.5}Practical Considerations}{59}{section.9.5}%
\contentsline {chapter}{\numberline {10}Complete Results and Analysis}{60}{chapter.10}%
\contentsline {section}{\numberline {10.1}Complete Performance Table}{60}{section.10.1}%
\contentsline {section}{\numberline {10.2}Key Findings}{60}{section.10.2}%
\contentsline {subsection}{\numberline {10.2.1}Finding 1: Linear Regression Dominates}{60}{subsection.10.2.1}%
\contentsline {subsection}{\numberline {10.2.2}Finding 2: Sentiment Provides Marginal Improvement}{61}{subsection.10.2.2}%
\contentsline {subsection}{\numberline {10.2.3}Finding 3: Hybrid Strategy Benefits RNNs (Empirically Verified)}{61}{subsection.10.2.3}%
\contentsline {subsection}{\numberline {10.2.4}Finding 4: Transformer Initially Fails, Then Succeeds with Proper Configuration}{61}{subsection.10.2.4}%
\contentsline {section}{\numberline {10.3}Statistical Significance Testing}{61}{section.10.3}%
\contentsline {chapter}{\numberline {11}Conclusions}{62}{chapter.11}%
\contentsline {section}{\numberline {11.1}Main Conclusions}{62}{section.11.1}%
\contentsline {section}{\numberline {11.2}Contributions to Knowledge}{63}{section.11.2}%
\contentsline {chapter}{\numberline {12}Additional Analysis and Deep Insights}{65}{chapter.12}%
\contentsline {section}{\numberline {12.1}Optimal Window Analysis for Sentiment Methods}{65}{section.12.1}%
\contentsline {subsubsection}{Mathematical Analysis of Autocorrelation}{65}{section*.5}%
\contentsline {subsubsection}{Effective Degrees of Freedom}{66}{section*.6}%
\contentsline {subsubsection}{Why Longer Windows Underperform}{66}{section*.7}%
\contentsline {subsection}{\numberline {12.1.1}TextBlob Window Analysis}{67}{subsection.12.1.1}%
\contentsline {subsection}{\numberline {12.1.2}Why FinBERT Shows Minimal Improvement from Rolling Means}{67}{subsection.12.1.2}%
\contentsline {subsubsection}{Mathematical Perspective}{68}{section*.8}%
\contentsline {section}{\numberline {12.2}Parameter Efficiency Analysis}{68}{section.12.2}%
\contentsline {subsection}{\numberline {12.2.1}Efficiency Metric Definition}{68}{subsection.12.2.1}%
\contentsline {subsection}{\numberline {12.2.2}Complete Efficiency Comparison}{69}{subsection.12.2.2}%
\contentsline {subsection}{\numberline {12.2.3}Dimensionality-Performance Trade-off}{69}{subsection.12.2.3}%
\contentsline {subsection}{\numberline {12.2.4}Daily Aggregated Sentiment}{70}{subsection.12.2.4}%
\contentsline {subsection}{\numberline {12.2.5}Effective Article Weight}{70}{subsection.12.2.5}%
\contentsline {section}{\numberline {12.3}Complete Execution Timeline}{70}{section.12.3}%
\contentsline {subsection}{\numberline {12.3.1}Actual Execution Breakdown}{70}{subsection.12.3.1}%
\contentsline {subsection}{\numberline {12.3.2}Performance Bottlenecks}{71}{subsection.12.3.2}%
\contentsline {subsection}{\numberline {12.3.3}Memory Usage Estimation}{72}{subsection.12.3.3}%
\contentsline {subsection}{\numberline {12.3.4}Computational Complexity}{72}{subsection.12.3.4}%
\contentsline {section}{\numberline {12.4}Comparative Analysis with Literature}{72}{section.12.4}%
\contentsline {subsection}{\numberline {12.4.1}Benchmark Comparison}{72}{subsection.12.4.1}%
\contentsline {subsection}{\numberline {12.4.2}Why Our Results Are Strong}{73}{subsection.12.4.2}%
\contentsline {subsection}{\numberline {12.4.3}AAPL Characteristics Favoring Prediction}{74}{subsection.12.4.3}%
\contentsline {subsection}{\numberline {12.4.4}Generalization Considerations}{75}{subsection.12.4.4}%
\contentsline {section}{\numberline {12.5}Summary of Key Insights}{75}{section.12.5}%
\contentsline {chapter}{\numberline {13}Final Summary}{76}{chapter.13}%
\contentsline {section}{\numberline {13.1}Research Questions Answered}{76}{section.13.1}%
\contentsline {subsection}{\numberline {13.1.1}Q1: Do rolling mean sentiment features improve predictions?}{76}{subsection.13.1.1}%
\contentsline {subsection}{\numberline {13.1.2}Q2: What is the optimal rolling window?}{76}{subsection.13.1.2}%
\contentsline {subsection}{\numberline {13.1.3}Q3: Can neural networks beat traditional methods?}{76}{subsection.13.1.3}%
\contentsline {subsection}{\numberline {13.1.4}Q4: Which neural architecture is best?}{77}{subsection.13.1.4}%
\contentsline {subsection}{\numberline {13.1.5}Q5: Are experiments free from lookahead bias?}{77}{subsection.13.1.5}%
\contentsline {subsection}{\numberline {13.1.6}Q6: Can outdated data be used to train foundational models?}{77}{subsection.13.1.6}%
\contentsline {subsection}{\numberline {13.1.7}Q7: Does cutting down transformer size (fewer attention heads, smaller feed-forward layers) help?}{78}{subsection.13.1.7}%
\contentsline {section}{\numberline {13.2}Key Takeaways}{79}{section.13.2}%
\contentsline {subsection}{\numberline {13.2.1}Best Performance}{79}{subsection.13.2.1}%
\contentsline {subsection}{\numberline {13.2.2}Largest Sentiment Improvement}{79}{subsection.13.2.2}%
\contentsline {subsection}{\numberline {13.2.3}Most Efficient Model}{79}{subsection.13.2.3}%
\contentsline {subsection}{\numberline {13.2.4}Most Important Factor}{80}{subsection.13.2.4}%
\contentsline {section}{\numberline {13.3}Reproducibility Statement}{80}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Code Availability}{80}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}Data Sources Documented}{80}{subsection.13.3.2}%
\contentsline {subsection}{\numberline {13.3.3}Hyperparameters Specified}{80}{subsection.13.3.3}%
\contentsline {subsection}{\numberline {13.3.4}Results Backed by Execution Logs}{81}{subsection.13.3.4}%
\contentsline {subsection}{\numberline {13.3.5}Execution Instructions}{81}{subsection.13.3.5}%
\contentsline {subsection}{\numberline {13.3.6}No Claims Without Evidence}{81}{subsection.13.3.6}%
\contentsline {chapter}{\numberline {A}Complete Hyperparameters}{83}{appendix.A}%
\contentsline {chapter}{\numberline {B}Mathematical Derivations}{85}{appendix.B}%
\contentsline {section}{\numberline {B.1}Derivation: Optimal Predictor Minimizing MAE}{85}{section.B.1}%
\contentsline {section}{\numberline {B.2}Derivation: Bias-Variance Decomposition}{85}{section.B.2}%
\contentsline {section}{\numberline {B.3}Derivation: Transformer Degeneracy}{86}{section.B.3}%
\contentsline {chapter}{\numberline {C}Code Structure}{87}{appendix.C}%
\contentsline {section}{\numberline {C.1}Reproducibility}{87}{section.C.1}%
\contentsline {chapter}{\numberline {D}Additional Visualizations}{89}{appendix.D}%
\contentsline {chapter}{\numberline {E}Data Availability}{94}{appendix.E}%
